{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/cac-nha-nghien-cuu-cong-bo-huan-luyen-thanh-cong-mo-hinh-ai-chi-voi-chua-den-50-usd.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-07 12:58:07",
  "summary": "Con số 50 USD khá ấn tượng, vì việc huấn luyện các mô hình AI tiên tiến thường tốn hàng nghìn đến hàng trăm nghìn USD chi phí điện toán do yêu cầu về tài nguyên máy tính cực lớn...",
  "content": "\nTheo Techcrunch, các nhà nghiên cứu AI tại Đại học Stanford và Đại học Washington vừa công bố một nghiên cứu, tiết lộ rằng họ đã huấn luyện thành công một mô hình AI \"lý luận\" chỉ với chưa đầy 50 USD tiền điện toán đám mây.\nTuy nhiên, cần hiểu rõ số tiền 50 USD, đây chính là tiền điện toán đám mây, nghĩa là chi phí mà nhóm nghiên cứu đã chi trả cho dịch vụ điện toán đám mây để huấn luyện mô hình AI.\nHUẤN LUYỆN MÔ HÌNH AI THƯỜNG TỐN HÀNG NGHÌN ĐẾN HÀNG TRĂM NGHÌN USD CHI PHÍ ĐIỆN TOÁN \nĐiện toán đám mây (cloud computing) là dịch vụ cho phép thuê tài nguyên máy tính (như CPU, GPU, bộ nhớ và lưu trữ) từ các nhà cung cấp như Amazon Web Services (AWS), Google Cloud, Microsoft Azure, hoặc Oracle Cloud. Trong trường hợp này, nhóm nghiên cứu chỉ tốn chưa đến 50 USD để sử dụng các tài nguyên này cho việc huấn luyện mô hình AI s1.\nCon số 50 USD khá ấn tượng, vì việc huấn luyện các mô hình AI tiên tiến thường tốn hàng nghìn đến hàng trăm nghìn USD chi phí điện toán do yêu cầu về tài nguyên máy tính cực lớn.\n“Mô hình lý luận 50 USD” này có tên là s1, cho thấy hiệu suất tương đương với các mô hình lý luận tiên tiến như o1 của OpenAI và R1 của DeepSeek khi kiểm tra khả năng toán học và lập trình. Mô hình s1 cùng với dữ liệu và mã nguồn để huấn luyện đã được công khai trên GitHub.\nNhóm nghiên cứu cho biết họ bắt đầu từ một mô hình AI có sẵn, sau đó tinh chỉnh bằng phương pháp distillation (chưng cất) — một quy trình giúp trích xuất khả năng \"lý luận\" từ một mô hình AI khác thông qua việc huấn luyện dựa trên các câu trả lời của mô hình đó.\nCụ thể, s1 được \"chưng cất\" (distilled) từ một trong các mô hình lý luận của Google có tên Gemini 2.0 Flash Thinking Experimental. Phương pháp \"chưng cất\" này cũng từng được các nhà nghiên cứu tại Đại học Berkeley sử dụng để tạo ra một mô hình lý luận AI với chi phí khoảng 450 USD vào tháng trước.\nAI ĐANG DẦN TRỞ THÀNH HÀNG HÓA PHỔ THÔNG?\nViệc các nhà nghiên cứu có thể tạo ra mô hình AI tiên tiến mà không cần hàng triệu đô la đầu tư khiến nhiều người cảm thấy phấn khích vì cơ hội đổi mới trong lĩnh vực AI đang được mở rộng. Tuy nhiên, mô hình s1 cũng đặt ra những câu hỏi nghiêm túc về việc AI đang dần trở thành hàng hóa phổ thông (commoditization).\nLiệu còn “hàng rào bảo vệ” nào cho các công ty lớn khi chỉ với số tiền nhỏ, người ta đã có thể tạo ra mô hình có chất lượng tương đương mô hình trị giá hàng triệu đô la?\nKhông có gì ngạc nhiên khi các phòng thí nghiệm AI lớn tỏ ra không hài lòng. OpenAI thậm chí đã cáo buộc DeepSeek thu thập dữ liệu trái phép từ API của mình để phục vụ cho việc chưng cất mô hình.\n\nDeepSeek từng gây sốc vì chi phí phát triển quá thấp so với OpenAI dù sau đó đã có những nghi vấn về mức chi phí này\n\nNói về s1, nhóm nghiên cứu đứng sau mô hình s1 đã tìm cách đơn giản nhất để đạt được hiệu suất lý luận mạnh mẽ và khả năng “test-time scaling” — tức cho phép mô hình AI suy nghĩ nhiều hơn trước khi đưa ra câu trả lời. Đây là một trong những đột phá của mô hình o1 của OpenAI, mà DeepSeek cùng nhiều phòng thí nghiệm AI khác đã cố gắng tái tạo bằng nhiều phương pháp khác nhau.\nBài nghiên cứu về s1 cho thấy các mô hình lý luận có thể được \"chưng cất\" (distilled) chỉ với một tập dữ liệu tương đối nhỏ bằng quy trình có tên supervised fine-tuning (SFT). Đây là phương pháp huấn luyện mà mô hình AI được hướng dẫn rõ ràng để bắt chước các hành vi nhất định dựa trên dữ liệu huấn luyện.\nSo với phương pháp học tăng cường quy mô lớn (reinforcement learning) mà DeepSeek sử dụng để phát triển mô hình R1 cạnh tranh với o1 của OpenAI, SFT thường tiết kiệm chi phí hơn.\nGoogle hiện cho phép truy cập miễn phí vào mô hình Gemini 2.0 Flash Thinking Experimental thông qua nền tảng Google AI Studio, nhưng có giới hạn sử dụng mỗi ngày.\nTuy nhiên, điều khoản của Google cấm việc đảo ngược kỹ thuật (reverse-engineering) mô hình của họ để phát triển các dịch vụ cạnh tranh với AI của công ty. Hiện Google chưa có bình luận chính thức về vấn đề này.\nMô hình s1 được phát triển dựa trên một mô hình AI nhỏ gọn có sẵn từ phòng thí nghiệm AI Qwen thuộc Alibaba. Mô hình này được cung cấp miễn phí để tải về.\nNhóm nghiên cứu đã tạo ra một tập dữ liệu chỉ gồm 1.000 câu hỏi được lựa chọn kỹ lưỡng, đi kèm với câu trả lời và quy trình \"suy nghĩ\" phía sau mỗi câu trả lời từ mô hình Gemini 2.0 Flash Thinking Experimental của Google.\nQuá trình huấn luyện s1 chỉ mất chưa đầy 30 phút với 16 GPU Nvidia H100. Theo Niklas Muennighoff, một nhà nghiên cứu tại Stanford tham gia dự án, chi phí thuê máy tính cần thiết hiện chỉ khoảng 20 USD.\nMột \"mẹo\" thú vị được nhóm nghiên cứu sử dụng để giúp s1 kiểm tra lại kết quả và kéo dài thời gian suy nghĩ là thêm từ “wait” (chờ) vào quá trình lý luận. Theo bài nghiên cứu, điều này giúp mô hình đưa ra câu trả lời chính xác hơn.\nVào năm 2025, Meta, Google và Microsoft dự kiến sẽ đầu tư hàng trăm tỷ USD vào cơ sở hạ tầng AI, trong đó một phần được dùng để huấn luyện các mô hình AI thế hệ mới.\nMức đầu tư khổng lồ này vẫn được xem là cần thiết để thúc đẩy sự đổi mới trong lĩnh vực AI. Phương pháp distillation (chưng cất) đã chứng minh là cách hiệu quả và tiết kiệm để tái tạo khả năng của các mô hình AI hiện có. Tuy nhiên, phương pháp này không giúp tạo ra các mô hình AI hoàn toàn mới với hiệu suất vượt trội so với những gì đang có trên thị trường.\n"
}