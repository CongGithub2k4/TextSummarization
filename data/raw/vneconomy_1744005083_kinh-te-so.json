{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/nvidia-cong-bo-chip-moi-phuc-vu-cho-phat-trien-mo-hinh-ai.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-07 12:51:23",
  "summary": "Tại Hội nghị AI thường niên dành cho các nhà phát triển - GPU Technology Conference (GTC) mới đây, Nvidia đã công bố những mẫu chip mới phục vụ cho việc xây dựng và phát triển mô hình trí tuệ nhân tạo…",
  "content": "\nGiám đốc Điều hành Nvidia Jensen Huang chính thức giới thiệu Blackwell Ultra, dòng chip mới được phát hành vào nửa cuối năm nay, và Vera Rubin, bộ xử lý đồ họa thế hệ tiếp theo, dự kiến ra mắt vào năm 2026, theo CNBC.\nDoanh thu của Nvidia tăng hơn sáu lần kể từ khi công ty chuyển mình, sau sự xuất hiện của ChatGPT hồi cuối năm 2022. Được sử dụng trong quá trình huấn luyện mô hình, \"GPU lớn\" của Nvidia luôn chiếm ưu thế trên thị trường AI tiên tiến.\nGiới nhà phát triển phần mềm và nhà đầu tư đang theo dõi sát sao các mẫu chip mới của công ty để xem liệu chúng có mang lại hiệu suất, hiệu quả đủ thuyết phục những khách hàng lớn nhất - công ty điện toán đám mây như Microsoft, Google và Amazon - tiếp tục chi hàng tỷ USD xây dựng trung tâm dữ liệu sử dụng chip Nvidia hay không?\nThông tin hôm thứ Ba (18/3) cũng là bài kiểm tra cho chu kỳ phát hành sản phẩm của Nvidia. Công ty đang nỗ lực công bố các dòng chip mới hàng năm. Trước khi AI bùng nổ, Nvidia chỉ phát hành chip mới hai năm một lần.\nHội nghị GTC ở San Jose, California cũng là dịp để Nvidia thể hiện sức mạnh. Đây là hội nghị trực tiếp thứ hai mà Nvidia tổ chức kể từ khi đại dịch, ước tính có khoảng 25.000 người tham dự cùng hàng trăm công ty thảo luận về cách họ sử dụng phần cứng Nvidia để phát triển AI. Hãng sản xuất ô tô Hoa Kỳ General Motors khẳng định sẽ sử dụng dịch vụ của Nvidia cho những chiếc xe thế hệ mới.\nKiến trúc chip Rubin sẽ mang tên nhà vật lý Richard Feynman, Nvidia chia sẻ tại sự kiện, tiếp tục truyền thống đặt tên các dòng chip theo tên nhà khoa học. Chip Feynman của Nvidia dự kiến có mặt trên thị trường vào năm 2028, theo nội dung trên slide mà ông Huang trình bày.\nNgoài ra, Nvidia cũng trưng bày một số sản phẩm và dịch vụ khác tại sự kiện. Hai chiếc PC được hỗ trợ bởi AI mang tên DGX Spark và DGX Station, có thể chạy mô hình AI lớn như Llama hoặc DeepSeek. Cùng với đó, bản cập nhật nhằm kết nối hàng trăm, hàng nghìn GPU với nhau nhằm hoạt động như một hệ thống thống nhất, cùng gói phần mềm Dynamo giúp người dùng tận dụng tối đa hiệu suất của chip cũng được giới thiệu.\nVERA RUBIN\nNvidia dự kiến xuất xưởng các hệ thống sử dụng dòng GPU thế hệ mới vào nửa cuối năm 2026. Hệ thống này bao gồm hai thành phần chính: một CPU mang tên Vera, và một thiết kế GPU mới, gọi là Rubin. Trong đó, tên Rubin được đặt theo tên nhà thiên văn học Vera Rubin.\nVera là thiết kế CPU tùy chỉnh đầu tiên của Nvidia và dựa trên thiết kế lõi mà hãng đặt tên là Olympus, công ty cho biết.\nTrước đây, khi cần CPU, Nvidia thường sử dụng thiết kế có sẵn từ Arm. Các công ty phát triển thiết kế lõi Arm tùy chỉnh, như Qualcomm và Apple, cho biết chúng có thể được tối ưu hóa và mang lại hiệu suất tốt hơn.\nThiết kế tùy chỉnh Vera nhanh gấp đôi so với CPU sử dụng trong các chip Grace Blackwell năm ngoái, theo thông báo từ Nvidia.\nKhi kết hợp với Vera, Rubin có thể xử lý 50 petaflops khi thực hiện suy luận (inference), gấp đôi so với 20 petaflops của chip Blackwell hiện tại. Rubin có thể hỗ trợ tới 288 gigabyte bộ nhớ tốc độ cao, một trong những thông số quan trọng mà nhà phát triển AI thường quan tâm.\nNvidia cũng đang thực hiện một số thay đổi, như Rubin thực tế là hai GPU. GPU Blackwell hiện tại trên thị trường thực chất là hai con chip riêng biệt được lắp ráp lại và làm việc như một chip duy nhất.\nBắt đầu từ Rubin, Nvidia sẽ gọi khi kết hợp hai hoặc nhiều die (lõi) tạo thành một chip duy nhất là GPU tách biệt. Vào nửa cuối năm 2027, Nvidia dự kiến phát hành chip \"Rubin Next\", kết hợp bốn die thành một chip, giúp tốc độ Rubin tăng gấp đôi, và công ty sẽ gọi đó là bốn GPU.\nNvidia thông báo, sản phẩm này sẽ được đóng gói trong giá đỡ gọi là Vera Rubin NVL144. Các phiên bản trước đây của giá đỡ Nvidia được gọi là NVL72.\n\nCEO Jensen Huang cùng một số sản phẩm mới tại sự kiện.\n\nBLACKWELL ULTRA\nBên cạnh Vera RuBin, Nvidia còn công bố phiên bản mới của dòng chip Blackwell, có tên là Blackwell Ultra.\nCon chip này có khả năng sản xuất nhiều token hơn mỗi giây, có nghĩa là có thể tạo ra nhiều nội dung hơn trong cùng một khoảng thời gian so với phiên bản tiền nhiệm, theo thông báo của công ty.\nTừ đây, nhà cung cấp dịch vụ đám mây có thể sử dụng Blackwell Ultra để cung cấp dịch vụ AI cao cấp cho ứng dụng nhạy cảm về thời gian, cho phép họ tạo ra doanh thu gấp 50 lần so với thế hệ chip Hopper, được phát hành năm 2023.\nBlackwell Ultra có phiên bản kết hợp hai chip với CPU Nvidia Arm, gọi là GB300, và phiên bản chỉ có GPU, gọi là B300. Sản phẩm cũng sở hữu phiên bản với tám GPU trong một blade máy chủ và phiên bản rack với 72 chip Blackwell.\nBốn công ty đám mây lớn nhất đã triển khai gấp ba lần số lượng chip Blackwell so với chip Hopper, Nvidia cho biết.\nDEEPSEEK\nMô hình DeepSeek R1 của Trung Quốc có thể khiến nhà đầu tư Nvidia lo ngại, nhưng Nvidia lại “hoan nghênh” phần mềm này. Nhà sản xuất chip tuyên bố sẽ sử dụng mô hình R1 để kiểm tra hiệu suất sản phẩm mới của mình.\nNhiều quan sát viên AI cho rằng mô hình DeepSeek, vốn được cho là yêu cầu ít chip hơn so với mô hình sản xuất tại Hoa Kỳ, đang đe dọa đến hoạt động kinh doanh của Nvidia.\nTuy nhiên, đầu năm nay, ông Huang khẳng định DeepSeek thực sự là tín hiệu tốt cho Nvidia. Bởi DeepSeek sử dụng quy trình \"reasoning\" (suy luận), yêu cầu nhiều sức mạnh tính toán hơn để cung cấp câu trả lời tối ưu cho người dùng. Hơn nữa, các chip Blackwell Ultra mới rất phù hợp với mô hình suy luận, Nvidia cho biết.\nCông ty đã tập trung phát triển chip để sản phẩm hiệu quả hơn khi thực hiện suy luận, vì vậy mô hình suy luận mới yêu cầu nhiều sức mạnh tính toán hơn trong quá trình triển khai, và chip Nvidia có thể xử lý được.\n\"Trong 2 đến 3 năm qua, một bước đột phá lớn đã xảy ra, một tiến bộ cơ bản trong trí tuệ nhân tạo đã xảy ra. Chúng tôi gọi nó là AI tác nhân (agentic AI)\", CEO Huang nói. \"Công nghệ có thể lý luận về cách trả lời hoặc giải quyết vấn đề vượt trội\".\n"
}