{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/google-huy-bo-cam-ket-khong-su-dung-ai-cho-vu-khi-giam-sat.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-07 12:58:02",
  "summary": "Google đã chính thức thay đổi chính sách trí tuệ nhân tạo (AI), loại bỏ một số hạn chế trước đây về việc sử dụng AI trong phát triển vũ khí và công cụ giám sát…",
  "content": "\nMới đây Google đã cập nhật bộ \"Nguyên tắc AI\" mới, trong đó công ty bỏ qua cam kết trước đây về việc không sử dụng trí tuệ nhân tạo (AI) phát triển ứng dụng gây hại, chẳng hạn như vũ khí hay công cụ giám sát, theo CNBC.\nTrong phiên bản trước của nguyên tắc AI, gã khổng lồ công nghệ Hoa Kỳ tuyên bố không theo đuổi \"vũ khí, công nghệ gây tổn hại trực tiếp đến con người, công nghệ thu thập hoặc sử dụng thông tin cho giám sát, vi phạm chuẩn mực quốc tế\". Tuy nhiên, những mục tiêu này hiện không hiển thị trên trang web Nguyên tắc AI của công ty.\nTheo bài viết trên blog của Google hôm đầu tuần này, được viết bởi ông Demis Hassabis, Giám đốc Điều hành Google DeepMind: \"Cuộc đua vị trí dẫn đầu AI trên toàn cầu đang diễn ra trong bối cảnh tình hình địa chính trị ngày càng phức tạp. Chúng tôi tin rằng các nền dân chủ nên chủ động phát triển AI, dựa trên giá trị cốt lõi như tự do, bình đẳng và tôn trọng quyền con người\".\nMột số nguyên tắc cập nhật phản ánh đúng tham vọng ngày càng lớn của Google trong việc cung cấp công nghệ và dịch vụ AI cho người dùng và khách hàng, bao gồm cả chính phủ các nước. \nThay đổi này cũng phù hợp với tuyên bố gần đây của lãnh đạo Thung lũng Silicon về cuộc đua AI giữa Hoa Kỳ và Trung Quốc. Giám đốc Công nghệ Palantir, Shyam Sankar, kỳ vọng \"sự nỗ lực trên toàn quốc có thể giúp chúng ta giành chiến thắng\".\nPhiên bản trước của bộ nguyên tắc AI nói rằng Google luôn \"xem xét các yếu tố xã hội và kinh tế\". Tuy nhiên, bản nguyên tắc AI mới nhấn mạnh Google sẽ \"hành động khi công ty tin rằng lợi ích chung lớn hơn các rủi ro và tác hại có thể xảy ra\".\nCũng trong nội dung bài viết, Google khẳng định \"tuân thủ nguyên tắc pháp luật quốc tế và quyền con người được công nhận rộng rãi – luôn đánh giá từng công việc cụ thể, cẩn thận để xem liệu lợi ích mang lại có lớn hơn rủi ro tiềm ẩn hay không\".\nBộ nguyên tắc AI mới của Google được báo cáo lần đầu bởi The Washington Post, trước khi công ty công bố kết quả tài chính quý IV. Báo cáo cho thấy Google không đạt kỳ vọng doanh thu của Phố Wall và khiến cổ phiếu công ty giảm 9% trong giao dịch ngoài giờ.\n\"Chúng tôi tin rằng mọi công ty, chính phủ và tổ chức chung giá trị nên hợp tác để tạo ra AI bảo vệ con người, thúc đẩy phát triển toàn cầu và hỗ trợ an ninh quốc gia\", Google nêu quan điểm trong bài viết.\nGoogle đã xây dựng nguyên tắc về trí tuệ nhân tạo (AI) vào năm 2018, sau khi từ chối gia hạn hợp đồng chính phủ mang tên Project Maven, giúp chính phủ phân tích và giải thích video từ drone tích hợp AI. Trước khi kết thúc thỏa thuận, hàng nghìn nhân viên ký đơn phản đối hợp đồng và hàng chục người đã từ chức để lên án hành động của Google. \nSau đó, công ty rút khỏi cuộc đấu thầu hợp đồng đám mây trị giá 10 tỷ USD với Lầu Năm Góc, một phần vì công ty \"không thể chắc chắn\" rằng hợp đồng này sẽ phù hợp với bộ nguyên tắc AI của mình, công ty cho biết vào thời điểm đó.\nKIỂM SOÁT “LỤC ĐỤC” NỘI BỘ\nDưới sự lãnh đạo của CEO Sundar Pichai, đội ngũ Google đã tích cực theo đuổi các hợp đồng với chính phủ liên bang, gây ra căng thẳng lớn trong nội bộ công ty.\nNăm ngoái, Google chấm dứt hợp đồng với hơn 50 nhân viên sau cuộc biểu tình phản đối Dự án Nimbus, hợp đồng trị giá 1,2 tỷ USD với Amazon, cung cấp dịch vụ điện toán đám mây, AI cho chính phủ và quân đội Israel. Ban lãnh đạo công ty khẳng định hợp đồng này không vi phạm bất kỳ nguyên tắc AI nào của công ty.\nTuy nhiên, một số tài liệu và báo cáo cho thấy thỏa thuận đồng ý để Google cung cấp cho Israel công cụ AI bao gồm phân loại hình ảnh, theo dõi đối tượng, cũng như điều khoản liên quan đến sản xuất vũ khí nhà nước. Tờ New York Times hồi tháng 12 đưa tin rằng bốn tháng trước khi ký kết Dự án Nimbus, lãnh đạo Google tỏ lo ngại việc ký kết hợp đồng có thể gây tổn hại đến uy tín công ty và \"dịch vụ đám mây của Google có thể được sử dụng trực tiếp hoặc liên quan đến hành vi vi phạm nhân quyền\".\nTrong khi đó, công ty cũng tăng cường kiểm soát các cuộc thảo luận trong nội bộ về xung đột địa chính trị như cuộc chiến ở Gaza.\nVào tháng 9, Google thắt chặt quy định đối với cuộc thảo luận trên diễn đàn nội bộ Memegen, hạn chế các thảo luận về nội dung địa chính trị, quan hệ quốc tế, xung đột quân sự, hành động kinh tế và tranh chấp lãnh thổ. Google hiện chưa trả lời yêu cầu bình luận.\n"
}