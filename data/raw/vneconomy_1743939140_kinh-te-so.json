{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/khi-ai-tu-xay-dung-ai-nhung-buoc-tien-cong-nghe-tiep-theo-co-the-khong-den-tu-con-nguoi.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-06 18:32:20",
  "summary": "Những diễn biến gần đây cho thấy, có thể con người đang tiến gần đến thời điểm AI tự nâng cấp và tự xây dựng thế hệ kế nhiệm…",
  "content": "\nDeepSeek từng gây chấn động khi công bố mô hình tư duy R1 hồi cuối tháng 1 vừa qua, châm châm ngòi cho những tranh luận gay gắt về cạnh tranh công nghệ Mỹ - Trung và tính hợp lý của các khoản đầu tư vào hạ tầng AI, kéo theo sự sụt giảm mạnh của cổ phiếu nhiều công ty AI hàng đầu.\nNhưng giữa những tranh cãi đó, một xu hướng quan trọng nhất trên hành trình tiến tới trí tuệ nhân tạo tổng quát (AGI) lại ít được bàn tới: vai trò ngày càng lớn của các hệ thống AI trong việc thiết kế, xây dựng và hoàn thiện thế hệ AI kế tiếp. Ngày càng nhiều AI đang tạo ra AI, tác giả George C. Lee II, đồng giám đốc của Viện Goldman Sachs toàn cầu.\nTrong báo cáo về R1, DeepSeek đã giải thích cách tận dụng các kỹ thuật như tạo dữ liệu tổng hợp, chưng cất mô hình và học tăng cường do máy vận hành để tạo ra một mô hình vượt trội so với tiêu chuẩn hiện tại. Mỗi phương pháp này đều có thể hiểu theo cách khác là khai thác năng lực của AI hiện có để hỗ trợ đào tạo một phiên bản tiên tiến hơn.\nDeepSeek không phải là đơn vị duy nhất sử dụng AI để cải tiến AI. Mark Zuckerberg từng dự đoán, các kỹ sư tầm trung tại Meta có thể sớm bị thay thế bởi AI, và Llama 3 (mô hình ngôn ngữ lớn - LLM của công ty này) “giúp chúng tôi thử nghiệm và lặp lại nhanh hơn, xây dựng những khả năng chúng tôi muốn hoàn thiện và mở rộng trong Llama 4”.\nJensen Huang, CEO Nvidia, cũng từng nói về việc tạo ra môi trường ảo – nơi các hệ thống AI giám sát việc đào tạo các hệ thống robot: “Chúng ta có thể tạo ra vô số vũ trụ song song, cho phép robot học cùng lúc theo 100.000 cách khác nhau”.\nĐiều này chưa hẳn đã chạm đến ngưỡng “điểm kỳ dị” – khi máy móc thông minh có thể tự sao chép và phát triển – nhưng là một điều mới mẻ và có thể mang tính đột phá.\nDù tiến bộ trong mô hình AI đang diễn ra với tốc độ chóng mặt, vẫn có những ý kiến cho rằng, sự phát triển của “quy luật mở rộng quy mô” (scaling laws) – nguyên lý cho thấy hiệu suất của AI tăng theo lượng dữ liệu, năng lượng và tính toán được cung cấp – có thể đang chậm lại. Nhưng sự ra mắt của DeepSeek, cùng với hàng loạt động thái từ các công ty khác sau đó, cho thấy những nhận định đó có thể đã bị phóng đại.\nTrên thực tế, những đổi mới trong phát triển AI đang mở ra những con đường mới – nơi mọi thứ đều do AI tự tạo ra. Tiến bộ không hề chậm lại, mà đang tăng tốc – nhờ AI.\nXU THẾ KHÔNG THỂ ĐẢO NGƯỢC\nMột trong những phương pháp lâu đời nhất để sử dụng AI tạo ra AI là thông qua dữ liệu tổng hợp, tức là sử dụng dữ liệu do AI tạo ra để tiếp tục đào tạo và tinh chỉnh các hệ thống AI khác.\nCụm từ “dữ liệu tổng hợp” có thể gợi ý rằng, những dữ liệu này kém chất lượng hơn dữ liệu “hữu cơ” (đơn cử như nội dung từ internet). Nhưng thực tế lại chứng minh điều ngược lại.\nTạo dữ liệu tổng hợp cho phép AI tạo ra những ví dụ huấn luyện thực tế, được thiết kế riêng cho các lĩnh vực hoặc tình huống hiếm gặp có thể không xuất hiện nhiều trong các bộ dữ liệu thực tế.\nDù vẫn có giới hạn – một nghiên cứu gần đây cho thấy sau vài vòng tạo dữ liệu tổng hợp, mô hình có thể xuống cấp nhanh chóng – nhưng kỹ thuật này vẫn có thể đẩy nhanh đổi mới trong những lĩnh vực mà thu thập dữ liệu thực rất khó khăn, chẳng hạn như hình ảnh y khoa hoặc mô hình hóa cấu trúc protein để phát triển thuốc mới.\n\nMột trong những phương pháp lâu đời nhất để sử dụng AI tạo ra AI là thông qua dữ liệu tổng hợp. \n\nMột kỹ thuật quan trọng khác mà DeepSeek nhấn mạnh là chưng cất mô hình, trong đó các mô hình lớn – tiêu tốn nhiều tài nguyên tính toán – truyền tải kiến thức và khả năng của chúng sang các mô hình nhỏ hơn, hiệu quả hơn. Phương pháp này giúp phổ biến các năng lực AI trong các mô hình mã nguồn mở, đồng thời, giúp các công ty đưa những khả năng này đến với nhiều người dùng hơn thông qua các phiên bản nhỏ hơn của mô hình có hiệu suất cao. Chưng cất giúp AI dễ mở rộng hơn bằng cách giảm kích thước mô hình, giúp việc tiếp cận và áp dụng dễ dàng hơn.\nHãy tưởng tượng, nếu mỗi sinh viên khi bước vào đại học đều mang theo toàn bộ kiến thức của tất cả sinh viên và giáo sư trước đó. Sau đó, sinh viên này được đưa vào một cuộc thi với hàng trăm sinh viên ảo khác, tất cả đều có cùng kiến thức, nhằm tối ưu hóa một mục tiêu nhất định.\nĐây chính là ý tưởng của học tăng cường do máy vận hành – một kỹ thuật trong đó AI tự cải thiện thông qua việc tự chơi, thử nghiệm và tinh chỉnh tư duy của chính mình.\nPhương pháp này đã đóng vai trò then chốt trong những đột phá AI nổi tiếng nhất, bao gồm chiến thắng của AlphaGo trước những kỳ thủ cờ vây hàng đầu thế giới. Việc tận dụng AI để tự thiết kế chương trình đào tạo mở ra một hướng phát triển hoàn toàn mới, chỉ bị giới hạn bởi khả năng của những cỗ máy ngày càng thông minh hơn trong việc khám phá điều mới mẻ.\nNHỮNG NHÀ KHOA HỌC AI\nMột trong những ứng dụng ấn tượng nhất của AI trong việc tinh chỉnh AI là mô hình “đồng khoa học” (co-scientist) của Google Gemini, một hệ thống AI đa tác nhân (multi-agent AI system) được thiết kế để mô phỏng phương pháp khoa học – nhưng ở quy mô và tốc độ siêu việt.\nAI đồng khoa học của Google tận dụng kỹ thuật “mở rộng tính toán khi suy luận” (test-time compute scaling), tức là sử dụng thêm tài nguyên tính toán trong quá trình suy luận, để mô phỏng tư duy khoa học, kiểm tra các giả thuyết khác nhau và liên tục tự đánh giá lại quy trình.\nNhờ đó, hệ thống này có thể kết hợp dữ liệu tổng hợp, học tăng cường và điều phối tác nhân AI theo từng lĩnh vực chuyên môn để tạo ra kết quả khoa học.\nHãy hình dung, một đội quân gồm những nhà khoa học có trình độ cao nhất thế giới, không bao giờ mệt mỏi, không bao giờ than phiền và không ngừng cải tiến – đó chính là mô hình này. Dù đây không phải là ví dụ trực tiếp về AI tạo ra AI, nhưng đang cho thấy những con đường mở rộng mới có thể tạo ra cách mạng trong các lĩnh vực khác.\nHãy mở rộng hình dung đó: nếu có một đội ngũ các nhà khoa học máy tính được thiết lập với mục tiêu tối ưu hóa tốc độ phát triển của LLMs? Đây chính là những gì Sakana AI, công ty có trụ sở tại Tokyo, mới công bố: một kỹ sư có tên CUDA AI – một hệ thống AI đa tác nhân hoàn toàn tự động.\nNói cách khác, đây là một hệ thống AI giúp tăng tốc đáng kể các hệ thống AI khác – nhanh hơn 10-100 lần so với phương pháp trước đó. AI đang tự xây dựng chính nó với tốc độ ngày càng nhanh.\nChúng ta phải chấp nhận rằng, con người không thể dự đoán chính xác cách những hệ thống AI này sẽ phát triển và những đổi mới nào có thể xuất hiện. Hầu hết các phát minh đều được sinh ra từ quá trình thử nghiệm và sai sót kéo dài – thường mất nhiều năm hoặc nhiều thập kỷ.\nNhưng những hệ thống AI này đang tái tạo quá trình “thử và sai” thông qua thử nghiệm không ngừng ở quy mô đáng kinh ngạc. Chúng ta hầu như không thể hình dung được khả năng, thậm chí cả sự sáng tạo, mà AI có thể đạt được khi chúng xử lý tính toán và tư duy ở mức độ ngày càng cao – có thể sớm vượt xa khả năng tưởng tượng của con người.\nNhững người theo dõi tiến bộ công nghệ chắc chắn sẽ chứng kiến một chặng đường đầy biến động trong những năm tới. Ngay cả khái niệm về “nhà sáng tạo” cũng có thể thay đổi, khi ngày càng nhiều đột phá đến không phải từ thành tựu của một cá nhân, mà từ những hệ thống AI liên tục cải tiến.\nTrong nhiều thập kỷ qua, con người đã xây dựng ngành khoa học máy tính và AI với hy vọng tạo ra những hệ thống có thể sao chép kiến thức và tư duy tốt nhất của loài người.\nNhưng những diễn biến gần đây cho thấy có thể chúng ta đang tiến gần đến thời điểm AI tự nâng cấp và xây dựng thế hệ kế nhiệm của chính nó. Những nhà phát minh vĩ đại tiếp theo – những người tìm ra phương pháp điều trị y học mới, tạo ra vật liệu mới, giải mã bí ẩn của vũ trụ hay nguyên tử – có lẽ sẽ không còn là con người nữa.\n"
}