{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/cac-trung-tam-du-lieu-ai-doi-nang-luong.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-07 12:52:02",
  "summary": "Nhu cầu năng lượng của các trung tâm dữ liệu AI đòi hỏi nhiều cải tiến chip hơn cùng các giải pháp tiết kiệm năng lượng…",
  "content": "\nCác trung tâm dữ liệu trí tuệ nhân tạo (AI) toàn cầu có thể tiêu thụ 7% điện năng của thế giới vào năm 2030 – tương đương mức sử dụng của Ấn Độ trong một năm. Nguyên nhân là bởi nhu cầu ứng dụng tăng vọt trong thời gian tới, bất chấp những tiến bộ gần đây như DeepSeek hứa hẹn triển vọng cải thiện hiệu suất huấn luyện và triển khai.\nNhận định này được ông Adam White, người đứng đầu bộ phận hệ thống điện và cảm biến tại Infineon – nhà sản xuất chip hàng đầu của châu Âu – chia sẻ với Nikkei Asia mới đây.\nVị này cho rằng, các mô hình ngôn ngữ lớn (LLM) hiệu quả hơn, như của DeepSeek, không những không làm giảm đầu tư vào trung tâm dữ liệu AI mà còn kích thích nhu cầu tính toán tăng mạnh hơn. \n\"Một số nguồn tin cho rằng con số 7% vẫn còn khá khiêm tốn\", ông White chia sẻ. \"Trong Infineon và mạng lưới đối tác của chúng tôi, chúng tôi tin rằng [DeepSeek và những tiến bộ tương tự] chỉ càng tạo ra thêm nhu cầu đối với các mô hình ngôn ngữ lớn và cả trung tâm dữ liệu\". Các yêu cầu tính toán ngày càng cao sẽ kéo theo mức tiêu thụ điện năng lớn hơn, ông nói thêm.\nNăm 2024, các trung tâm dữ liệu AI tiêu thụ khoảng 2% tổng điện năng toàn cầu. \nNhu cầu điện gia tăng tạo ra cơ hội lớn cho các nhà sản xuất bán dẫn chuyên về linh kiện điện như Infineon. Công ty dự đoán doanh thu từ lĩnh vực trung tâm dữ liệu AI sẽ tăng đáng kể và có thể đạt 1 tỷ euro (1,1 tỷ USD) trong vòng hai năm tới, theo White. \nÔng White lấy ví dụ, một bộ xử lý đồ họa (GPU) AI điển hình vào năm 2022 tiêu thụ khoảng 0,4 kilowatt (kW), nhưng đến năm 2024, con số này đã vượt 2 kW.\nTrong khi đó, tiêu thụ của một giá máy chủ AI đã tăng từ khoảng 60 kW vào năm 2022 lên hơn 150 kW vào năm 2024 – một mức tăng ngoài sức tưởng tượng trước đây. Để so sánh, một hộ gia đình trung bình tại Mỹ tiêu thụ khoảng 1,25 kW điện liên tục, tương đương khoảng 900 kWh mỗi tháng. \nNhững bước nhảy vọt này đang thúc đẩy nhu cầu về các giải pháp năng lượng hiệu quả hơn, ông nhấn mạnh.\nTrước đây, các nhà sản xuất chip lớn khác như TSMC, Samsung Electronics và SK Hynix cũng đã xác định mức tiêu thụ điện là một trong những thách thức chính đối với sự phát triển của AI.\nGoldman Sachs Research từng dự báo, nhu cầu điện của trung tâm dữ liệu toàn cầu sẽ tăng 50% vào năm 2027 và có thể tăng vọt tới 165% vào cuối thập kỷ này. \nLãnh đạo cấp cao của Infineon cho biết, công ty đang hợp tác chặt chẽ với các nhà sản xuất chip AI hàng đầu và các nhà cung cấp dịch vụ đám mây ngay từ giai đoạn thiết kế ban đầu để tích hợp các mô-đun cấp điện vào thế hệ máy chủ AI tiếp theo. \nHãng chip này cũng thông báo sẽ ra mắt dòng sản phẩm chip điện mới để đáp ứng nhu cầu đang tăng, bao gồm các mô-đun cấp điện theo chiều dọc, hệ thống pin dự phòng và bộ nguồn. \nCác bộ nguồn trung tâm dữ liệu mới nhất của Infineon kết hợp chip silicon với các chất bán dẫn dải rộng như silicon carbide (SiC) và gallium nitride (GaN), cung cấp đầu ra từ 8 kW đến thế hệ 12 kW mới sẽ ra mắt trong quý II năm nay. Các chất bán dẫn dải rộng này sẽ cho phép tần số chuyển mạch cao hơn, mật độ điện năng lớn hơn và hiệu suất chuyển đổi năng lượng tốt hơn so với silicon truyền thống.\nTrong khi đó, các hệ thống pin dự phòng cung cấp nguồn điện tạm thời trong trường hợp mất điện lưới, giúp tránh tổn thất dữ liệu trong quá trình đào tạo AI. Hệ thống này cũng hỗ trợ cắt giảm đỉnh công suất – tức là điều chỉnh mức tiêu thụ điện để giảm áp lực cho hệ thống. \nÔng White cho biết trước đây, khách hàng chưa quan tâm nhiều đến gián đoạn nguồn điện, nhưng hiện nay, nhu cầu đối với các giải pháp như vậy đang gia tăng tại Bắc Mỹ và châu Âu, do an ninh năng lượng trở nên quan trọng hơn bao giờ hết đối với quá trình huấn luyện và phát triển AI. \n"
}