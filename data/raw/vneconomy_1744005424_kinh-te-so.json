{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/ceo-openai-khang-dinh-chi-phi-su-dung-ai-se-giam-10-lan-moi-nam.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-07 12:57:04",
  "summary": "Chi phí sử dụng AI sẽ giảm khoảng 10 lần mỗi 12 tháng, và giá càng thấp thì mức độ sử dụng càng tăng cao...",
  "content": "\nCEO của OpenAI, Sam Altman, vừa đưa ra ba quan sát quan trọng về sự phát triển nhanh chóng của trí tuệ nhân tạo (AI) tổng quát. Một trong những điểm đáng chú ý nhất là chi phí sử dụng AI đang giảm mạnh với tốc độ 10 lần mỗi năm.\nBA QUAN SÁT QUAN TRỌNG CỦA SAM ALTMAN VỀ AI\n\"Chi phí sử dụng AI sẽ giảm khoảng 10 lần mỗi 12 tháng, và giá càng thấp thì mức độ sử dụng càng tăng cao”, CEO Altman nhấn mạnh. Ông cũng lấy ví dụ về chi phí token từ GPT-4 vào đầu năm 2023 đến GPT-4o vào giữa năm 2024, khi giá mỗi token đã giảm khoảng 150 lần trong khoảng thời gian này. \"Định luật Moore từng thay đổi thế giới với tốc độ gấp đôi sau mỗi 18 tháng; AI sẽ còn mang lại sự thay đổi mạnh mẽ hơn rất nhiều\".\n“Chi phí sử dụng AI\" mà CEO OpenAI đề cập đến chính là các chi phí để vận hành hoặc truy cập một hệ thống AI có cùng mức độ thông minh hoặc khả năng xử lý. Nói cách khác, nếu một mô hình AI có khả năng xử lý và suy luận ở một mức độ cố định (ví dụ như GPT-4), thì chi phí để chạy nó hoặc truy cập vào nó sẽ giảm theo thời gian. Các chi phí này bao gồm chi phí điện toán (Compute Cost) - chi phí sử dụng GPU/TPU để huấn luyện và suy luận trên AI; Chi phí hạ tầng (Infrastructure Cost) - bao gồm phần cứng, lưu trữ dữ liệu, và bảo trì hệ thống; Chi phí truy cập (Access Cost) - mức giá mà người dùng phải trả để sử dụng AI, như phí thuê bao hoặc giá mỗi token trên API.\nVí dụ, GPT-4o vào giữa năm 2024 có cùng hoặc thậm chí khả năng cao hơn GPT-4 vào đầu năm 2023, nhưng giá truy cập đã giảm tới 150 lần. Điều này có nghĩa là chi phí để sử dụng một mức độ AI tương tự đang giảm rất nhanh, giúp AI trở nên phổ biến hơn trong nhiều ứng dụng.\nCụ thể, theo Business Insider, CEO OpenAI đã có ba quan sát quan trọng. Thứ nhất, trí tuệ của một mô hình AI tỷ lệ thuận với logarit của nguồn lực được sử dụng để đào tạo và vận hành nó. Đây chính là mối quan hệ giữa trí tuệ của một mô hình AI và nguồn lực sử dụng để huấn luyện nó. Thứ hai, chi phí sử dụng AI giảm khoảng 10 lần mỗi 12 tháng, dẫn đến việc sử dụng AI ngày càng phổ biến hơn. Thứ ba, giá trị kinh tế - xã hội của sự gia tăng trí tuệ theo cấp số cộng có tính chất siêu cấp số nhân.\nNhững quan sát của Altman được đưa ra trong bối cảnh ngành AI đang có những bước tiến lớn, bao gồm sự xuất hiện của DeepSeek – một đối thủ nặng ký với mô hình AI siêu tiết kiệm chi phí, đối lập với mức giá đắt đỏ của ChatGPT Pro (200 USD/tháng). DeepSeek được xem là một nhân tố đặc biệt trong cuộc đua AI, vì nó chứng minh rằng các công ty khởi nghiệp có thể tham gia vào lĩnh vực này mà không cần đầu tư hàng tỷ đô la.\nAltman cũng nhấn mạnh rằng trí tuệ của một mô hình AI phụ thuộc chặt chẽ vào các nguồn lực dành cho việc huấn luyện và vận hành nó. \"Những nguồn lực này chủ yếu bao gồm khả năng tính toán để đào tạo, dữ liệu và khả năng tính toán để suy luận”, ông cho biết.\n\"Có vẻ như chúng ta có thể chi tiêu một lượng tiền khổng lồ và vẫn nhận được những cải tiến liên tục và có thể dự đoán được. Các định luật về khả năng mở rộng đã chứng minh điều này một cách chính xác trên nhiều cấp độ khác nhau\".\nNhững nhận định của Altman được đưa ra chỉ vài tuần sau khi OpenAI công bố kế hoạch đầu tư 500 tỷ USD vào dự án Stargate nhằm xây dựng các trung tâm dữ liệu trên khắp nước Mỹ để thúc đẩy sự phát triển của AI.\nNăm ngoái, đã có báo cáo cho rằng các phòng thí nghiệm AI hàng đầu như OpenAI, Google và Anthropic đang gặp khó khăn trong việc phát triển mô hình AI tiên tiến do thiếu nội dung chất lượng cao để huấn luyện. Tuy nhiên, Altman và cựu CEO của Google, Eric Schmidt, đã bác bỏ những tuyên bố này, khẳng định rằng không có dấu hiệu nào cho thấy các định luật mở rộng đã bắt đầu làm chậm sự tiến bộ của AI. \"Không có bức tường giới hạn nào cả\", ông Altman nhấn mạnh.\nÁP LỰC LỢI NHUẬN, MICROSOFT VÀ GOOGLE ĐÃ ĐIỀU CHỈNH GIÁ DỊCH VỤ AI\nLiên quan đến chi phí sử dụng các mô hình AI, mới đây, Microsoft và Google đã điều chỉnh giá dịch vụ AI để tối ưu lợi nhuận. Theo Reuters, Microsoft và công ty mẹ của Google - Alphabet, đã chi tổng cộng 99 tỷ USD để xây dựng hạ tầng AI. Vì thế, giờ đây, họ đang chịu áp lực phải chứng minh lợi nhuận từ khoản đầu tư này vào năm 2025.\n\nBằng cách đưa AI vào gói cơ bản và tăng giá, Google và Microsoft đang buộc tất cả khách hàng – kể cả những người không sử dụng AI – phải đóng góp vào chi phí phát triển AI.\n\nTrước áp lực đó, cả Microsoft và Google đã có những thay đổi lớn trong giá dịch vụ AI trong bộ công cụ văn phòng của họ. Những tính năng AI như tóm tắt và tạo nội dung tài liệu, tích hợp với các ứng dụng như Word và Excel đã được điều chỉnh về giá.\nCụ thể, trước đây, gói AI Gemini Business của Google là một tùy chọn bổ sung có giá 240 USD/năm cho Google Workspace (có giá 144 USD/năm). Giờ đây, Gemini Business sẽ đi kèm miễn phí, nhưng Google tăng giá Google Workspace lên 168 USD/năm (tăng 17%). Và người dùng không thể từ chối việc tăng giá này.\nCòn với Microsoft, trước đây, Copilot Pro AI là một tùy chọn bổ sung có giá 240 USD/năm cho Microsoft 365 (tên cũ là Office 365). Nay, Microsoft gộp Copilot Pro vào các gói Microsoft 365 tiêu dùng, đồng thời tăng giá gói cá nhân từ 70 USD lên 100 USD/năm (tăng 43%). Người dùng có thể chọn giữ giá cũ nhưng phải từ chối tính năng AI. Dù vậy, AI vẫn bị giới hạn mức sử dụng; nếu muốn sử dụng không giới hạn, người dùng phải trả 240 USD/năm. Gói doanh nghiệp Microsoft 365 Copilot vẫn giữ mô hình add-on với giá 360 USD/năm.\nNhững điều chỉnh này cho thấy các mô hình giá cũ không thu hút đủ khách hàng. Bằng cách đưa AI vào gói cơ bản và tăng giá, Google và Microsoft đang buộc tất cả khách hàng – kể cả những người không sử dụng AI – phải đóng góp vào chi phí phát triển AI. Họ kỳ vọng rằng đủ số người dùng sẽ nhận thấy giá trị của AI và sẵn sàng chi tiền nhiều hơn trong tương lai.\nNgành công nghệ đang đối mặt với bài toán khó: làm thế nào để xây dựng một mô hình kinh doanh bền vững cho AI khi chi phí vận hành trung tâm dữ liệu AI ngày càng cao. Trước đây, phần mềm có thể mở rộng nhanh vì chi phí phục vụ mỗi khách hàng mới rất thấp. Nhưng AI lại khác – mỗi người dùng mới đều tốn kém. Vì thế, Microsoft và Google đang tìm cách tối ưu hóa doanh thu từ AI ngay từ bây giờ.\n"
}