{
  "category": "kinh-te-so",
  "url": "https://vneconomy.vn/khai-niem-moi-chung-cat-ai-khien-nhieu-ga-khong-lo-cong-nghe-lo-lang.htm",
  "source": "vneconomy",
  "scraped_at": "2025-04-07 12:57:58",
  "summary": "Việc một công ty AI ra đời, sử dụng kỹ thuật nhằm \"chưng cất\" kiến thức của một số mô hình AI đi trước đang gây nhiều lo ngại…",
  "content": "\nNgành công nghệ và thị trường chứng khoán hiện nay đang cố gắng lý giải cách một công ty nhỏ bé của Trung Quốc, ít được biết đến, lại có thể phát triển ra chatbot trí tuệ nhân tạo (AI) với chi phí thấp hơn rất nhiều các tập đoàn khác trên thế giới, theo Kr Asia.\nMô hình AI mới được phát triển bởi DeepSeek, công ty khởi nghiệp công nghệ mới được thành lập cách đây một năm. Dù tuổi đời ngắn, sức mạnh của DeepSeek có thể sánh ngang hoặc thậm chí vượt trội so với những mô hình AI nổi tiếng như ChatGPT của OpenAI, Gemini của Google, CoPilot của Microsoft hay Llama của Meta.\nPHƯƠNG PHÁP “CHƯNG CẤT”\nMột trong những giả thuyết được giới chuyên gia trong ngành nhận định đây là phương pháp chưng cất (distillation), một kỹ thuật huấn luyện AI sử dụng mô hình \"mẹ\" lớn hơn để huấn luyện mô hình \"con\" nhỏ hơn nhưng có khả năng hoạt động nhanh hơn.\nDeepSeek tuyên bố đạt được mức độ hiệu suất tương đương với mô hình o1 của OpenAI với chi phí chỉ bằng một phần nhỏ thông qua “thiết kế tối ưu hóa thuật toán, khung và phần cứng”.\nSự kiện này dẫn đến đợt bán tháo mạnh mẽ trên thị trường chứng khoán công nghệ khi các nhà đầu tư bắt đầu phân vân về việc liệu phương pháp tiết kiệm chi phí của công ty Trung Quốc có phải là dấu hiệu cho thấy cuộc đua đầu tư AI và sự thống trị của các ông lớn công nghệ Hoa Kỳ sắp kết thúc.\nMột số người trong ngành nghi ngờ rằng công ty có thể đã lợi dụng thành tựu của OpenAI. Sự nghi ngờ ngày càng tăng khi Bloomberg đưa tin rằng Microsoft và OpenAI tiến hành điều tra liệu DeepSeek có thu thập dữ liệu từ OpenAI bất hợp pháp để huấn luyện mô hình hay không. Hôm 28/1, OpenAI xác nhận với Financial Times rằng họ thấy dấu hiệu của việc chưng cất, mặc dù không công bố chi tiết bằng chứng.\nMicrosoft và DeepSeek chưa phản hồi yêu cầu bình luận.\nChưng cất thực tế không phải là kỹ thuật mới và không quá gây tranh cãi. Minitron của Nvidia và Falcon 3, phát triển bởi Viện Sáng tạo Công nghệ UAE, đều sử dụng phương pháp này, dùng mô hình ngôn ngữ lớn (LLM) của riêng họ làm mô hình \"mẹ\". Phương pháp này trở nên phổ biến từ năm 2024 trong bối cảnh nhu cầu sử dụng LLM trong doanh nghiệp ngày càng lớn.\nTuy nhiên, mô hình LLM lớn lại “khó xử lý và bạn sẽ cần số lượng đơn vị xử lý đồ họa (GPU) khổng lồ để triển khai”, kỹ sư tại một công ty AI ở Nhật Bản cho biết.\nGPU là lý do chính khiến hệ thống AI trở nên đắt đỏ. Ví dụ, chip H100 đặc trưng của Nvidia có giá từ 30.000 đến 35.000 USD mỗi chiếc. Kỹ thuật chưng cất giúp giảm đáng kể thời gian và chi phí phát triển, đồng thời tạo ra mô hình có khả năng vận hành nhanh hơn so với đối thủ.\nNĂNG LỰC THỰC SỰ CỦA DEEPSEEK?\n“Vậy liệu DeepSeek cùng mô hình chi phí thấp có phụ thuộc nhiều vào phương pháp chưng cất hơn là đổi mới sáng tạo hay không?” ông Kirk Boodry, nhà phân tích tại Astris Advisory Japan, cho biết với Nikkei Asia. “Điều này đang được bàn luận khá nhiều. Mọi người đều tự hỏi: ‘Tôi không biết bao nhiêu phần trong số này thực sự tiên tiến’”.\nÔng Kazuhiro Sugiyama, Giám đốc Tư vấn tại Omdia, tỏ ra hoài nghi về khả năng DeepSeek có thể thay đổi mạnh mẽ hệ sinh thái AI hiện tại. Ông cho rằng tác động của công ty này là “tạm thời và hạn chế”, hơn nữa ông chỉ ra rằng mặc dù chatbot của công ty Trung Quốc cho thấy những dấu hiệu đổi mới ấn tượng, nhưng ngành công nghiệp vẫn cần kiểm chứng thêm dưới góc độ bền vững.\nCác nhà phân tích cũng đặt câu hỏi liệu chatbot DeepSeek có thực sự được phát triển với chỉ một phần ngân sách so với đối thủ phương Tây hay không.\n“Khi mọi người nói về những con số gây chú ý của DeepSeek, như vài tháng phát triển hay chi tiêu 6 triệu USD, họ đang nói đến một mô hình rất cụ thể”, ông Boodry từ Astris chia sẻ. “Các con số mà mọi người nhắc đến có lẽ là quá thấp”.\nCông ty Trung Quốc này đã công bố bài báo vào tháng 12 năm 2024, trong đó ghi nhận chi phí cho mô hình V3 của họ là 5,6 triệu USD. Tuy nhiên, con số này không bao gồm chi phí liên quan đến nghiên cứu và thử nghiệm trước đó. Trong khi, chi phí huấn luyện cho GPT-4 của OpenAI được ước tính vượt quá 100 triệu USD.\nÔng Sugiyama dự đoán sẽ có nhiều công ty gia nhập cuộc đua phát triển mô hình ngôn ngữ lớn (LLM), nhưng vị trí thị trường của các ông lớn như OpenAI sẽ không thay đổi. Ông nhận định các mô hình AI sẽ dần \"phân cực\". \nMột số công ty lớn như Microsoft và Google tiếp tục đầu tư vào mô hình lớn, mạnh mẽ hơn để sử dụng trong các dịch vụ của họ, trong khi những doanh nghiệp nhỏ hơn sẽ phát triển mô hình nhỏ hơn, rẻ hơn và hiệu quả hơn, phù hợp với thị trường cụ thể.\nTHÀNH TỰU ĐÁNG GHI NHẬN\n\nNhiều chuyên gia cho rằng, dù ít hay nhiều, DeepSeek xứng đáng được công nhận.\n\nMặc dù có sự phóng đại nhưng giới chuyên gia không nghi ngờ về việc DeepSeek đã đạt được điều gì đó xứng đáng được công nhận.\nNgay cả khi công ty sử dụng phương pháp chưng cất, điều đó vẫn không đủ để phát triển thành mô hình hoàn chỉnh. “Công ty cần có kiến thức chuyên môn để sử dụng GPU một cách hiệu quả và cần tìm ra cách thực hiện huấn luyện phức tạp”, chẳng hạn như kết hợp nhiều mô hình khác nhau để đưa ra câu trả lời tốt hơn, một kỹ sư giấu tên cho hay.\nMột kỹ sư AI khác nói rằng anh “không ngạc nhiên” khi một công ty như DeepSeek xuất hiện đột ngột. “Bởi xu hướng hiện nay là giảm kích thước mô hình AI… Theo thời gian, sẽ có nhiều cách để đạt mục tiêu này”.\n"
}